{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case-1: Transfer Learning\n",
    "        \n",
    "        [Split planes metadata into source and target according to the location of the data (Southern/Northern)\n",
    "        Taking Sourthen as a source and Northern as a target\n",
    "        source.csv = source metadata\n",
    "        target.csv = target metadata]\n",
    "        \n",
    "        Source [train(90%),validation(10%)]\n",
    "        Target [test(100%)]\n",
    "        \n",
    "        **metadata is used only for splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Planes dataset\n",
    "\n",
    "data = pd.read_json('planesnet.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add an ID\n",
    "\n",
    "data['ID'] = data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source metadata - use for source planes ID only\n",
    "\n",
    "source_planes = pd.read_csv(\"source.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_planes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and validation set [useing source planes ID]\n",
    "\n",
    "train=[]\n",
    "val=[]\n",
    "for d in range(len(source_planes)):\n",
    "    if ((source_planes['NorthernCalifornia'][d] == 0) and (source_planes['SplitLabel'][d] == 'Train')):\n",
    "        train.append(data.iloc[source_planes['ImageID'][d]])\n",
    "    if ((source_planes['NorthernCalifornia'][d] == 0) and (source_planes['SplitLabel'][d] == 'Validate')):\n",
    "        val.append(data.iloc[source_planes['ImageID'][d]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train),len(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=[]\n",
    "y_train=[]\n",
    "for d in range(len(train)):\n",
    "    a=np.array(train[d]['data'])\n",
    "    x_train.append(a.reshape((3,20*20)).T.reshape((20,20,3)))\n",
    "    y_train.append(np.array(train[d]['labels']))\n",
    "x_train = np.array(x_train)\n",
    "y_train=np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val=[]\n",
    "y_val=[]\n",
    "for d in range(len(val)):\n",
    "    a=np.array(val[d]['data'])\n",
    "    x_val.append(a.reshape((3,20*20)).T.reshape((20,20,3)))\n",
    "    y_val.append(np.array(val[d]['labels']))\n",
    "x_val = np.array(x_val)\n",
    "y_val=np.array(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Target metadata - use for target planes ID only\n",
    "\n",
    "target_planes = pd.read_csv(\"target.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_planes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test set [using target planes ID]\n",
    "\n",
    "test=[]\n",
    "for d in range(len(target_planes)):\n",
    "    if ((target_planes['NorthernCalifornia'][d] == 1) and (target_planes['SplitLabel'][d] == 'Test')):\n",
    "        test.append(data.iloc[target_planes['ImageID'][d]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=[]\n",
    "y_test=[]\n",
    "for d in range(len(test)):\n",
    "    a=np.array(test[d]['data'])\n",
    "    x_test.append(a.reshape((3,20*20)).T.reshape((20,20,3)))\n",
    "    y_test.append(np.array(test[d]['labels']))\n",
    "x_test = np.array(x_test)\n",
    "y_test=np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape, y_train.shape, x_val.shape ,y_val.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (2, 2), padding='same',\n",
    "                 input_shape=x_train.shape[1:],name = 'layer_1'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),name='layer_2'))\n",
    "model.add(Activation('relu',name = 'layer_3'))\n",
    "\n",
    "model.add(Conv2D(64, (2, 2),padding='same',name = 'layer_4'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),name='layer_5'))\n",
    "model.add(Activation('relu',name = 'layer_6'))\n",
    "\n",
    "model.add(Dropout(0.2,name = 'layer_7'))\n",
    "\n",
    "model.add(Flatten(name='layer_8'))\n",
    "\n",
    "\n",
    "model.add(Dense(256,name='layer_N9'))\n",
    "model.add(Activation('relu',name = 'layer_N10'))\n",
    "\n",
    "model.add(Dropout(0.4,name = 'layer_N11'))\n",
    "model.add(Dense(128,name='layer_N12'))\n",
    "model.add(Activation('relu',name = 'layer_N13'))\n",
    "\n",
    "model.add(Dropout(0.4,name = 'layer_N14'))\n",
    "model.add(Dense(1, activation='sigmoid',name='layer_N15'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "                rescale=1./255,\n",
    "                )\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "                rescale=1./255,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator\n",
    "\n",
    "train_generator = train_datagen.flow(x_train, y_train, batch_size=500)\n",
    "validation_generator = test_datagen.flow(x_val,y_val, batch_size=500)\n",
    "test_generator = test_datagen.flow(x_test,y_test,batch_size=100,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "\n",
    "history = model.fit_generator(\n",
    "                    train_generator,\n",
    "                    steps_per_epoch = len(train_generator),\n",
    "                    epochs = epochs,\n",
    "                    validation_data = validation_generator,\n",
    "                    validation_steps= len(validation_generator),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy \n",
    "\n",
    "scores = model.evaluate_generator (test_generator, verbose=0)\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_generator(test_generator)\n",
    "y_pred=y_pred>0.5\n",
    "y_pred=np.asarray(y_pred,dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "\n",
    "target_names = ['No Planes', 'Planes']\n",
    "print(classification_report(y_test, y_pred, target_names= target_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
