{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case-3: Fine-tuning\n",
    "        \n",
    "        [Split planes metadata into source and target according to the location of the data (Southern/Northern)\n",
    "        Taking Sourthen as a source and Northern as a target\n",
    "        source.csv = source metadata\n",
    "        target.csv = target metadata\n",
    "        setDifferenceNorthern-Southern_lc_t=5.csv = targeted images metadata (from target dataset)]\n",
    "        \n",
    "        sourceCNN.h5 = pre-trained model from source (Source(s+n)_target(t-n).ipynb)\n",
    "        \n",
    "        -- All the layers are frozen accept second convolutional layer\n",
    "        \n",
    "        **metadata is used only for splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import random\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Planes dataset\n",
    "\n",
    "data = pd.read_json('planesnet.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add an ID\n",
    "\n",
    "data['ID'] = data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Targeted images ID for targeted transfer learning\n",
    "\n",
    "targeted_images = pd.read_csv(\"setDifferenceNorthern-Southern_lc_t=5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(targeted_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Target metadata - collecting target planes ID\n",
    "\n",
    "target_planes = pd.read_csv(\"target.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target data for targeted transfer learning [set difference]\n",
    "\n",
    "for d in range(len(targeted_images)):\n",
    "    target_planes = target_planes[target_planes.ImageID != targeted_images['ImageID'][d]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the index\n",
    "\n",
    "target_planes = target_planes.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(target_planes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_planes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train, target_test= train_test_split(target_planes, test_size=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_val, target_test= train_test_split(target_test, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(target_train),len(target_val),len(target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train = target_train.reset_index()\n",
    "target_val = target_val.reset_index()\n",
    "target_test = target_test.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "for d in range(len(target_train)):\n",
    "    train.append(data.iloc[target_train['ImageID'][d]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = []\n",
    "for d in range(len(target_val)):\n",
    "    val.append(data.iloc[target_val['ImageID'][d]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = []\n",
    "for d in range(len(target_test)):\n",
    "    test.append(data.iloc[target_test['ImageID'][d]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=[]\n",
    "y_train=[]\n",
    "for d in range(len(train)):\n",
    "    a=np.array(train[d]['data'])\n",
    "    x_train.append(a.reshape((3,20*20)).T.reshape((20,20,3)))\n",
    "    y_train.append(np.array(train[d]['labels']))\n",
    "x_train = np.array(x_train)\n",
    "y_train=np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val=[]\n",
    "y_val=[]\n",
    "for d in range(len(val)):\n",
    "    a=np.array(val[d]['data'])\n",
    "    x_val.append(a.reshape((3,20*20)).T.reshape((20,20,3)))\n",
    "    y_val.append(np.array(val[d]['labels']))\n",
    "x_val = np.array(x_val)\n",
    "y_val=np.array(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=[]\n",
    "y_test=[]\n",
    "for d in range(len(test)):\n",
    "    a=np.array(test[d]['data'])\n",
    "    x_test.append(a.reshape((3,20*20)).T.reshape((20,20,3)))\n",
    "    y_test.append(np.array(test[d]['labels']))\n",
    "x_test = np.array(x_test)\n",
    "y_test=np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape, y_train.shape, x_val.shape ,y_val.shape,x_test.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (2, 2), padding='same',\n",
    "        input_shape=x_train.shape[1:],trainable = False, name = 'layer_1'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),trainable = False, name='layer_2'))\n",
    "model.add(Activation('relu',trainable = False, name = 'layer_3'))\n",
    "\n",
    "model.add(Conv2D(64, (2, 2),padding='same',trainable = True,name = 'layer_4_Fine_tune'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),trainable = True,name='layer_5_Fine_tune'))\n",
    "model.add(Activation('relu',trainable = True,name = 'layer_6_Fine_tune'))\n",
    "\n",
    "model.add(Dropout(0.2,trainable = False,name = 'layer_7'))\n",
    "\n",
    "model.add(Flatten(name='layer_8'))\n",
    "\n",
    "model.add(Dense(256,trainable = False,name='layer_N9'))\n",
    "model.add(Activation('relu',trainable = False,name = 'layer_N10'))\n",
    "\n",
    "model.add(Dropout(0.4,trainable = False,name = 'layer_N11'))\n",
    "model.add(Dense(128,trainable = False,name='layer_N12'))\n",
    "model.add(Activation('relu',trainable = False,name = 'layer_N13'))\n",
    "\n",
    "model.add(Dropout(0.5,trainable = False,name = 'layer_N14'))\n",
    "model.add(Dense(1, activation='sigmoid',trainable = False,name='layer_N15'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model weights\n",
    "\n",
    "from keras.models import load_model\n",
    "model.load_weights('sourceCNN.h5',by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(\n",
    "                rescale=1./255,\n",
    "                )\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "                rescale=1./255,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow(x_train, y_train, batch_size=500)\n",
    "validation_generator = test_datagen.flow(x_val,y_val, batch_size=500)\n",
    "test_generator = test_datagen.flow(x_test,y_test,batch_size=100,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "data_augmentation = True\n",
    "history = model.fit_generator(\n",
    "                    train_generator,\n",
    "                    steps_per_epoch = len(train_generator),\n",
    "                    epochs = epochs,\n",
    "                    validation_data = validation_generator,\n",
    "                    validation_steps= len(validation_generator),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "\n",
    "scores = model.evaluate_generator (test_generator, verbose=0)\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_generator(test_generator)\n",
    "y_pred=y_pred>0.5\n",
    "y_pred=np.asarray(y_pred,dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "\n",
    "target_names = ['No Planes', 'Planes']\n",
    "print(classification_report(y_test, y_pred, target_names= target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
